{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 토큰 분류\n",
    "- [강좌링크](https://wikidocs.net/166830)\n",
    "\n",
    "#### 다음과 같이 문장의 각 토큰에 레이블을 지정하는 모든 문제를 포함:\n",
    "- NER(Named Entity Recognition): 개체명 인식\n",
    "- POS(Part-Of-Speech tagging): 문장의 각 단어에 대한 특정 품사를 지정\n",
    "- Chunking: 동일한 개체명 혹은 엔티티에 속한 토큰 찾기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c6bf76295e27ba"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터 준비\n",
    "토큰 분류에 적합한 Reuters의 주요 뉴스 기사가 포함된 CoNLL-2003 데이터셋 사용\n",
    "\n",
    "## CoNLL-2003 데이터셋"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "604899eebc9b77e3"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.399722200Z",
     "start_time": "2023-08-24T00:22:56.262573500Z"
    }
   },
   "id": "35bf9559a43da1be"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    train: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 14041\n    })\n    validation: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3250\n    })\n    test: Dataset({\n        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n        num_rows: 3453\n    })\n})"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.403721900Z",
     "start_time": "2023-08-24T00:22:58.399722200Z"
    }
   },
   "id": "e7ebe53ff34aac50"
  },
  {
   "cell_type": "markdown",
   "source": [
    "NER, POS, Chunking에 대한 레이블이 데이터셋에 포함되어있다. 입력된 텍스트가 문장이나 문서로 표현되지 않고 단어의 목록으로 표현된다. `token` 칼럼은 subword tokenization을 위해 여전히 토크나이저를 통과해야하는 pre-tokenization된 입력이라는 의미에서 word가 포함되어있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1309dbccc421de6d"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(raw_datasets[\"train\"][0][\"tokens\"])\n",
    "print(raw_datasets[\"train\"][0][\"ner_tags\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.407721800Z",
     "start_time": "2023-08-24T00:22:58.403721900Z"
    }
   },
   "id": "b34732d5261519ab"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "ner_feature"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.413722100Z",
     "start_time": "2023-08-24T00:22:58.407721800Z"
    }
   },
   "id": "e2a4a176c2c9c936"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.414721700Z",
     "start_time": "2023-08-24T00:22:58.411722600Z"
    }
   },
   "id": "bbf839af1b323aaf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이제 레이블을 디코딩함으로써 다음과 같은 결과를 볼 수 있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187f05c7fcc4353f"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "label_names_ner_tags = raw_datasets[\"train\"].features[\"ner_tags\"].feature.names\n",
    "label_names_pos_tags = raw_datasets[\"train\"].features[\"pos_tags\"].feature.names\n",
    "label_names_chunk_tags = raw_datasets[\"train\"].features[\"chunk_tags\"].feature.names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.417722Z",
     "start_time": "2023-08-24T00:22:58.416722100Z"
    }
   },
   "id": "120b1c2d8fb5e1b4"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to   boycott British lamb . \n",
      "B-ORG O       B-MISC O    O    O       B-MISC  O    O \n",
      "NNP   VBZ     JJ     NN   TO   VB      JJ      NN   . \n",
      "B-NP  B-VP    B-NP   I-NP B-VP I-VP    B-NP    I-NP O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "ner_tags = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "pos_tags = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
    "chunk_tags = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
    "\n",
    "sentence = \"\"\n",
    "ner_str = \"\"\n",
    "pos_str = \"\"\n",
    "chunk_str = \"\"\n",
    "\n",
    "for word, ner, pos, chunk in zip(words, ner_tags, pos_tags, chunk_tags):\n",
    "    ner_tag = label_names_ner_tags[ner]\n",
    "    pos_tag = label_names_pos_tags[pos]\n",
    "    chunk_tag = label_names_chunk_tags[chunk]\n",
    "    max_length = max(len(word), len(ner_tag), len(pos_tag), len(chunk_tag))\n",
    "    \n",
    "    sentence += word + \" \" * (max_length - len(word) + 1)\n",
    "    ner_str += ner_tag + \" \" * (max_length - len(ner_tag) + 1)\n",
    "    pos_str += pos_tag + \" \" * (max_length - len(pos_tag) + 1)\n",
    "    chunk_str += chunk_tag + \" \" * (max_length - len(chunk_tag) + 1)\n",
    "\n",
    "print(sentence)\n",
    "print(ner_str)\n",
    "print(pos_str)\n",
    "print(chunk_str)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.422946900Z",
     "start_time": "2023-08-24T00:22:58.419721800Z"
    }
   },
   "id": "b9502dfd94679e4b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 데이터 처리\n",
    "텍스트를 토큰 ID로 변환해야 모델이 해당 입력을 이해할 수 있다. 토큰 분류 작업의 경우 이미 단어로 분할(pre-tokenization)된 입력이 존재한다는 것인데 토크나이저 API는 이를 매우 쉽게 처리할 수 있다. `bert-base-cased` 토크나이저 모델을 다운로드하고 fast tokenizer인지 확인한 후 pre-tokenized 입력을 토큰화하려면 `is_split_into_words=True`를 지정하여 `tokenizer`를 실행한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c8a8b2155e4a984"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n",
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "print(tokenizer.is_fast)\n",
    "\n",
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "print(inputs.tokens())\n",
    "print(inputs.word_ids())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.691337600Z",
     "start_time": "2023-08-24T00:22:58.424721800Z"
    }
   },
   "id": "447facdfee24f57f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "토큰과 일치되도록 레이블 확장하기\n",
    "1. 특수 토큰의 레이블 ID는 -100(사용할 손실함수 cross entropy에서 무시되는 인덱스)\n",
    "2. 위 토큰 식별자 리스트에서 첫번째 7에 해당하는 토큰의 레이블은 B-로, 두번째 7에 해당하는 토큰의 레이블은 I-로 시작한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f351bdaef496a5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "# [CLS], [SEP] 2 개의 특수 토큰에 -100 할당하고 두 개의 토크으로 분할된 토큰에 대해 0 추가\n",
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # 새로운 단어의 시작\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # 특수 토큰\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # 이전 토큰과 동일한 단어에 소속된 토큰\n",
    "            label = labels[word_id]\n",
    "            \n",
    "            # 만약 레이블이 B-XXX면 I-XXX로 변경\n",
    "            if label % 2 == 1:\n",
    "                label += 1\n",
    "            \n",
    "            new_labels.append(label)\n",
    "    return new_labels\n",
    "\n",
    "print(ner_tags)\n",
    "print(align_labels_with_tokens(ner_tags, inputs.word_ids()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.692846Z",
     "start_time": "2023-08-24T00:22:58.691337600Z"
    }
   },
   "id": "741aa53a34d0bc99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위와 비슷하지만 하나의 단어에 하나의 레이블만 지정하고 해당 단어의 다른 하위 토큰에 무시될 토큰을 입력하면 손실에 크게 기여하는 많은 하위 토큰으로 분할되는 긴 단어를 회피할 수 있다. 레이블을 입력 ID와 정렬할 수 있도록 변경한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f73f75a717a349f6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, -100, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "def align_only_one_label(labels, word_ids):\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # 새로운 단어의 시작 토큰\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        else:\n",
    "            new_labels.append(-100)\n",
    "    return new_labels\n",
    "\n",
    "print(ner_tags)\n",
    "print(align_only_one_label(ner_tags, inputs.word_ids()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:58.699845500Z",
     "start_time": "2023-08-24T00:22:58.694845800Z"
    }
   },
   "id": "54803d6e1a184e1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "전체 데이터셋을 전처리하기 위해 모든 입력을 토큰화하고 모든 레이블에 `align_labels_with_tokens()`를 적용해야 한다.\n",
    "\n",
    "fast tokenizer의 장점을 활용하려면 `batched_true` 옵션을 사용한 `Dataset.map()` 메서드를 사용한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4a3cf9aa19dac30f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "533d0b95a3934d108e768712660bd5a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "336d07e9dab24099b12bf8d39b03bd4d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b3d4e24f9f7400ba8eb5f16e3b78e6e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 14041\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3250\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3453\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# 다중 텍스트(batch)를 입력받아 토큰화하고 레이블 할당하는 함수\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "    \n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    \n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        # new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "        new_labels.append(align_only_one_label(labels, word_ids))\n",
    "        \n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched = True,\n",
    "    remove_columns = raw_datasets[\"train\"].column_names\n",
    ")\n",
    "\n",
    "print(tokenized_datasets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:22:59.254028700Z",
     "start_time": "2023-08-24T00:22:58.701845500Z"
    }
   },
   "id": "3d18b2bcc957c18d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Trainer API를 이용한 Fine-Tuning\n",
    "\n",
    "실제 코드는 3장과 동일하나 batch와 metric 계산 기능만 변경한다.\n",
    "\n",
    "### Data Collation\n",
    "앞서 살펴본 `DataCollatorWithPadding`은 입력(input ids, attention mask, token type ids)에 대해서 패딩을 수행하기 때문에 여기서 사용 불가능하다.\n",
    "\n",
    "여기서는 레이블도 입력과 같은 방식으로 패딩되어야 동일한 크기를 유지하고 -100을 패딩값으로 사용해야 손실 계산 시 무시된다.\n",
    "\n",
    "따라서 이를 만족하는 ***DataCollatorForTokenClassification*** 을 사용한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "811e307fb45e1167"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer = tokenizer)\n",
    "\n",
    "# Test\n",
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "print(len(batch[\"input_ids\"][0]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:00.730514100Z",
     "start_time": "2023-08-24T00:22:59.256029100Z"
    }
   },
   "id": "30d5372eaff4da11"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 평가 기준 (Metrics)\n",
    "\n",
    "`Trainer`가 매 epoch마다 metrics을 계산하도록 하려면 predictions 및 labels 배열을 입력받아 메트릭 이름과 해당 평가 결과값이 포함된 딕셔너리를 반환하는 `compute_metrics()` 함수를 정의해야 한다. 토큰 분류 예측 평가하는데 많이 사용되는 전통적인 프레임워크는 *seqeval*이다. 이 메트릭을 사용하기 위해 **seqeval** 라이브러리를 먼저 설치해야 한다.(anaconda에서 설치 불가)\n",
    "\n",
    "설치가 완료되면 `evaluate` 라이브러리의 `load()` 함수를 통해 로드할 수 있다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e34afe36caf5643"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[2023-08-24 09:23:03,213] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "\n",
    "metric = load(\"seqeval\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:04.952405200Z",
     "start_time": "2023-08-24T00:23:00.731516Z"
    }
   },
   "id": "8b026d90301e804d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "이 메트릭은 우리가 일반적으로 알고있는 표준적인 정확도 accuracy가 아니다. 실제로는 레이블 목록을 정수가 아닌 문자열로 가져오므로 예측 결과와 정답 레이블을 메트릭에 전달하기 전에 디코딩해야 한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19732698d91b3806"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "labels = [label_names[i] for i in labels]\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:04.962455700Z",
     "start_time": "2023-08-24T00:23:04.955801200Z"
    }
   },
   "id": "ccf0dbb143079b77"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "{'MISC': {'precision': 1.0,\n  'recall': 0.5,\n  'f1': 0.6666666666666666,\n  'number': 2},\n 'ORG': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n 'overall_precision': 1.0,\n 'overall_recall': 0.6666666666666666,\n 'overall_f1': 0.8,\n 'overall_accuracy': 0.8888888888888888}"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = labels.copy()\n",
    "predictions[2] = \"O\" # 가짜 예측 생성 (Germany의 B-MISC => O)\n",
    "metric.compute(predictions = [predictions], references = [labels])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:04.968134800Z",
     "start_time": "2023-08-24T00:23:04.960452300Z"
    }
   },
   "id": "6ef2bf940260f268"
  },
  {
   "cell_type": "markdown",
   "source": [
    "위에서 보면 상당히 많은 정보가 출력된다. 전체뿐만 아니라 개별 개체 타입에 대한 정확도, 대현율, F1 점수를 구할 수 있다. 위의 메트릭 계산함수를 수정하여 각자 원하는 점수들을 얻을 수 있도록 수정 가능하다.\n",
    "\n",
    "아래에 구현된 `compute_metrics()` 함수는 먼저 logits의 argmax를 가져와 predictions으로 변환한다. 늘 그렇듯, logits과 확률이 비례하므로 softmax를 적용할 필요까지는 없다. 그런 다음 레이블과 예측을 정수에서 문자열로 변환해야한다. 레이블이 -100인 모든 값을 제거한 다음 결과를 `metric.compute()` 메서드에 전달한다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "42fe808b7153332e"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    # 무시된 인덱스들 제거하고 레이블로 변환\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    \n",
    "    all_metrics = metric.compute(predictions = true_predictions, references = true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"]\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:04.974031Z",
     "start_time": "2023-08-24T00:23:04.969090400Z"
    }
   },
   "id": "f542f91b037a06bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 모델 정의하기\n",
    "`AutoModelForTokenClassification` 모델 사용\n",
    "\n",
    "이 모델 사용 시 주요 사항은 가지고 있는 레이블 수에 대한 정보를 전달하는 것이다. 이는 `num_labels` 인수를 사용하는 것이지만 올바른 레이블 대응 정보 label correspondences를 설정하는 것이 좋다."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62de7e572bab6717"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {str(i): label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")\n",
    "\n",
    "# 올바른 수의 레이블이 지정되었는지 확인\n",
    "model.config.num_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:05.748773600Z",
     "start_time": "2023-08-24T00:23:04.973098800Z"
    }
   },
   "id": "a58dc31364cfcb19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## model fine-tuning\n",
    "\n",
    "### Training argument와 Trainer를 사용한 Fine-Tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb2b59dfd99f2b79"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingArguments(\n",
      "_n_gpu=1,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_backend=None,\n",
      "ddp_broadcast_buffers=None,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=epoch,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=2e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=0,\n",
      "log_level=passive,\n",
      "log_level_replica=warning,\n",
      "log_on_each_node=True,\n",
      "logging_dir=../../models/7.1/model/runs/Aug24_09-23-05_DESKTOP-0KK9DHO,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=../../models/7.1/model,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=[],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=../../models/7.1/model,\n",
      "save_on_each_node=False,\n",
      "save_safetensors=False,\n",
      "save_steps=500,\n",
      "save_strategy=epoch,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.01,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir = \"../../models/7.1/model\",\n",
    "    overwrite_output_dir = True,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    save_strategy = \"epoch\",\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 3,\n",
    "    weight_decay = 0.01,\n",
    "    disable_tqdm = False\n",
    ")\n",
    "\n",
    "print(args)\n",
    "\n",
    "# 드럽게 오래 걸려서 사용자 정의 학습으로 넘어감"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:23:05.820306Z",
     "start_time": "2023-08-24T00:23:05.750780300Z"
    }
   },
   "id": "93c88181977a9f16"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer.Trainer object at 0x7f84c8df4bb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongg/.virtualenvs/HF_Transformers/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='5268' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/5268 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=5268, training_loss=0.043871788247209116, metrics={'train_runtime': 436.9696, 'train_samples_per_second': 96.398, 'train_steps_per_second': 12.056, 'total_flos': 921792849708600.0, 'train_loss': 0.043871788247209116, 'epoch': 3.0})"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"validation\"],\n",
    "    data_collator = data_collator,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer = tokenizer\n",
    ")\n",
    "\n",
    "print(trainer)\n",
    "\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:30:25.585603900Z",
     "start_time": "2023-08-24T00:23:05.822305700Z"
    }
   },
   "id": "6c77be18474d9ec7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 사용자 정의 학습 루프\n",
    "\n",
    "### 학습을 위한 전체 준비"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd250461f04196c0"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# DataLoader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle = True,\n",
    "    collate_fn = data_collator,\n",
    "    batch_size = 8\n",
    ")\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"validation\"],\n",
    "    collate_fn = data_collator,\n",
    "    batch_size = 8\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label = id2label,\n",
    "    label2id = label2id\n",
    ")\n",
    "\n",
    "# AdamW optimizer: Adam + Weight decay\n",
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr =  2e-5)\n",
    "\n",
    "# Accelerator\n",
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:30:26.250786900Z",
     "start_time": "2023-08-24T00:30:25.587916800Z"
    }
   },
   "id": "99392b7f85ba7dbf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "`dataloader`를 `accelerator.prepare()`로 보냈으므로 그 크기를 사용해 training_steps를 계산할 수 있다.\n",
    "\n",
    "데이터로더를 생성한 후에는 데이터셋의 개수를 변경하기 때문에 항상 아래 작업을 수행해야한다.\n",
    "\n",
    "(learning_rate가 0까지 줄어드는 고전적인 linear schedule을 사용한다.)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d17648d968960c2a"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 3\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer = optimizer,\n",
    "    num_warmup_steps = 0,\n",
    "    num_training_steps = num_training_steps\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:30:26.256787100Z",
     "start_time": "2023-08-24T00:30:26.250786900Z"
    }
   },
   "id": "a6c9146efb7ae6e0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training loop"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba49c83ce455ce6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/5268 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7170604e5dfc4821a5af11cf5eb5fd95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0: {'precision': 0.9488387748232918, 'recall': 0.9415497661990648, 'f1': 0.9451802179379716, 'accuracy': 0.9906740391729294}\n",
      "epoch: 1: {'precision': 0.9498485358465163, 'recall': 0.9422370617696161, 'f1': 0.946027489104928, 'accuracy': 0.9908687356411354}\n",
      "epoch: 2: {'precision': 0.9498485358465163, 'recall': 0.9422370617696161, 'f1': 0.946027489104928, 'accuracy': 0.9908687356411354}\n"
     ]
    }
   ],
   "source": [
    "# 평가 부분을 단순화하기 위해 metric 객체의 입력을 구성하기 위해서 예측과 레이블을 가져와 문자열 목록으로 변환하는 다음의 postprocess() 함수를 정의\n",
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "    \n",
    "    # 무시할 인덱스 제거 후 레이블 변환\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for p, l in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions\n",
    "\n",
    "\"\"\"\n",
    "이제 학습 루프를 작성\n",
    "학습 진행 방식을 표시하기 위해 progressbar tqdm 사용\n",
    "\n",
    "루프는 세 부분으로 구성됨:\n",
    "- training: train_dataloader에서 반복적으로 batch 가져오기, forward pass, backward pass 및 최적화 단계\n",
    "- evaluation: 하나의 batch에서 모델의 예측 결과를 얻은 후 다음 작업 수행\n",
    "    - 두 프로세스가 입력과 레이블을 다른 모양으로 padding했을 수 있으므로 gather() 호출 전에 예측과 레이블을 동일한 모양으로 만들기 위해 accelerator.pad_across_processes()를 사용.\n",
    "    - 결과를 metric.add_batch()로 보내고 평가 루프가 끝나면 metric.compute를 호출\n",
    "- save: 모델과 토크나이저 저장\n",
    "\"\"\"\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "        \n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "    \n",
    "    # evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        \n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "        \n",
    "        # 취합 대상인 predictions와 labels를 패딩하기 위해 필요함..\n",
    "        predictions = accelerator.pad_across_processes(predictions, dim=-1, pad_index = -100)\n",
    "        labels = accelerator.pad_across_processes(labels, dim=-1, pad_index = -100)\n",
    "        \n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "        \n",
    "        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions = true_predictions, references = true_labels)\n",
    "        \n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch: {epoch}:\",\n",
    "\t\t{\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # save\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(\"../../models/7.1/model\", save_function=accelerator.save)\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(\"../../models/7.1/model\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:41:41.685183Z",
     "start_time": "2023-08-24T00:34:40.282817400Z"
    }
   },
   "id": "2808f9ee60d911af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use Fine-Tuned Model\n",
    "\n",
    "pipeline 사용해 로컬 모델 사용하기"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2caa25256bece8d"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "[{'entity_group': 'PER', 'score': 0.99833626, 'word': 'S', 'start': 11, 'end': 12}, {'entity_group': 'PER', 'score': 0.8255458, 'word': '##ylva', 'start': 12, 'end': 16}, {'entity_group': 'PER', 'score': 0.59038144, 'word': '##in', 'start': 16, 'end': 18}, {'entity_group': 'ORG', 'score': 0.74982303, 'word': 'Hu', 'start': 33, 'end': 35}, {'entity_group': 'MISC', 'score': 0.6438937, 'word': '##gging', 'start': 35, 'end': 40}, {'entity_group': 'ORG', 'score': 0.8391467, 'word': 'Face', 'start': 41, 'end': 45}, {'entity_group': 'LOC', 'score': 0.99860966, 'word': 'Brooklyn', 'start': 49, 'end': 57}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "model_checkpoint = \"../../models/7.1/model\"\n",
    "token_classifier = pipeline(\"token-classification\", model = model_checkpoint, aggregation_strategy = \"simple\")\n",
    "print(token_classifier(\"My name is Sylvain and I work at Hugging Face in Brooklyn.\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-24T00:42:15.817009600Z",
     "start_time": "2023-08-24T00:42:11.379416Z"
    }
   },
   "id": "a1a8ff1ae95617cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-24T00:32:37.895612300Z"
    }
   },
   "id": "b75742ed4ecb42a1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
